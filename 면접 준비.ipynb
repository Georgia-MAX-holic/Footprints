{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQlsZlXunR8K5+EZJgYBNP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Georgia-MAX-holic/Footprints/blob/main/%EB%A9%B4%EC%A0%91%20%EC%A4%80%EB%B9%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 지도 학습, 비지도학습, 반지도학습 , 강화학습 \n",
        "\n",
        "  - 지도학습, 비지도학습, 반지도학습, 강화학습 \n",
        "\n",
        "  - 온라인 학습과 배치 학습 \n",
        "\n",
        "  - 사례 기반 학습과 모델 기반 학습 "
      ],
      "metadata": {
        "id": "OJuL82iMY_UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9nhtXEZDUp2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "지도학습 ( Supervised Learning)\n",
        "\n",
        "- 지도학습: 알고리즘에 학습시키는 데이터와 그 데이터의 답이라고 할 수 있는 레이블(label)값이 포함되어야 한다. \n",
        "\n",
        "- 지도학습방법 : 회귀(Regression)은 예측변수(Predictor Variable)이라는 특성(Feature)를 사용하여 최종적인 결과를 예측하는 것인데 특정한 값을 예측한다면 분류(Classification)은 어떤 집단으로 분류할 수 있을지를 예측한다고 볼 수 있음 . \n",
        "\n",
        "분류에 널리 쓰이는 회귀로는 로지스틱이 있으며 클래스에 속할 확률 구할 수 있음 \n",
        "\n",
        "\n",
        "  - k-Nearest Neighbors\n",
        "  - Linear Regression\n",
        "  - Logistic Regression\n",
        "  - SVM(Support Vector Machine)\n",
        "  - Decision Tree\n",
        "  - Random Forest\n",
        "  - Nerual Network\n"
      ],
      "metadata": {
        "id": "UVmUBjovUpz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "비지도학습 ( Unsupervised Learning)\n",
        "\n",
        "- 비지도학습은 지도학습에서 필요한 레이블이 필요하지 않은 학습방법이다.\n",
        "\n",
        "- 대표적인 비지도학습에는 계층군집(클러스터링, Clustering), 시각화(Visualization)와 차원축소(Demension Reduction), 연관 규칙 학습(Association Rule Learning)이 있다.\n",
        "\n",
        "\n",
        "- Clustering : 작은 그룹으로 세분화\n",
        "\n",
        "  - K-means\n",
        "\n",
        "  - 계층 군집 분석 (HCA, Hierachical Cluster Analysis)\n",
        "\n",
        "  - 기댓값 최대화(Expectation Maximization)\n",
        "\n",
        "- Visualization & Demension Reduction : 시각화는 레이블이 없는 고차원의 데이터를 넣으면 이차원이나 삼차원의 표현으로 만든다는 뜻, 차원축소는 정보손실을 최소화하면서 데이터를 간소화하는 특성추출과 관련.\n",
        "\n",
        "  - 주성분 분석(PCA, Principal Component Analysis)\n",
        "\n",
        "  - Kernel PCA\n",
        "\n",
        "  - 지역적 선형 임베딩(LLE, Locally-Linear Embedding)\n",
        "\n",
        "  - t-SNE (t-distributed Stochastic Neighbor Embedding)\n",
        "\n",
        "- Association Rule Learning : 대량의 데이터에서 특성 간의 유의미한 관계를 찾음.\n",
        "\n",
        "    - Apriori\n",
        "    - Eclat\n",
        "\n",
        "- 반 지도학습 ( Semisupervised Learning) \n",
        "\n",
        "   - 반지도학습 혹은 준지도학습이라고 불리는 이 학습법은 레이블이 일부만 있어도 데이터를 다룰 수 있다.대부분의 반지도학습 알고리듬은 지도 학습과 비지도 학습의 조합으로 이루어져있다.\n",
        "\n",
        "   - 구글 포토 호스팅 서비스나 아이폰의 인물 사진처럼 여러 명의 인물 사진을 올리면 자동으로 사람을 인식하여 학습시킨다. 이 사람들이 누구인가하는 정보로 사람의 레이블이 주어지면 편리하게 해당 사람이 들어간 사진을 찾을 수 있다.\n",
        "\n",
        "\n",
        "- 강화학습(Reinforcement Learning) \n",
        "\n",
        " - 학습하는 시스템을 에이전트(Agent)라고 부르며 환경(Environment)을 관찰하여 행동(Action)을 실행하고 보상(Reward)을 받는다. 시간이 지나면서 가장 큰 보상을 얻기 위해 정책(Policy)이라고 부르는 최상의 전략을 스스로 학습하게 된다. 정책은 주어진 상황에서 에이전트가 어떻게 행동해야하는지를 판단한다. "
      ],
      "metadata": {
        "id": "yxDz1HPkW9Dn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 회귀와 분류 \n",
        "- 회귀 : 회귀(regression) 는 예측하고자 하는 타겟값이 실수, 즉 숫자인 경우 이다. 그리고 회귀는 예측 결과가 연속성을 지닌다.\n",
        "\n",
        "- 분류 : 분류(classification) 는 예측하고자 하는 타겟값이 범주형 변수인 경우 이다. 회귀와는 다르게 분류는 예측 결과가 연속성을 지니지 않는다. 연속성을 지니는 연속값이 아닌 이산값을 가지고 있다.  "
      ],
      "metadata": {
        "id": "uryaPK0HYoMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hold-Out Cross Validation과 K-Fold Cross Validation의 차이\n",
        "\n",
        "- hold-out은 데이터셋을 훈련셋과 테스트셋으로 분리합니다. 예를들어, 데이터셋의 80%를 훈련셋으로 삼아 모델을 훈련시키고, 나머지 20%를 테스트셋으로 이용해서 성능을 평가하는 것이죠. 그런데 훈련셋과 테스트셋으로만 나눠서 모델의 성능을 평가하다보면, 테스트셋이 모델의 파라미터 설정에 큰 영향을 미치게 됩니다. 모델이 테스트셋에 오버피팅될 가능성이 있게 되는 것이죠.\n",
        "\n",
        "\n",
        "- k-fold 교차검증은 데이터셋을 k개의 서브셋으로 분리합니다. 5-fold면 5개의 서브셋으로 분리해주는 것이죠. 그 다음에 하나의 서브셋만 테스트에 사용하고 나머지 k-1개의 서브셋은 훈련에 사용합니다. 이것을 k번 반복합니다. 이렇게 k번 측정한 성능지표를 평균냄으로 최종적으로 모델의 성능을 평가합니다. "
      ],
      "metadata": {
        "id": "IVNmdNdQZELp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 랜덤 포레스트와 Decision tree차이 \n",
        "\n",
        "- 결정 트리는 학습 데이터에 오버피팅 하는 경향이 있음, 랜덤 포레스트는 훈련을 통해 구성해놓은 다수의 나무로부터 분류 결과를 취합해서 결론을 얻는것 \n",
        "\n",
        "- 오버피팅을 피하기 위해 임의의 숲을 구성하는것, 다수의 나무로부터 구성하는것, 다수의 나무들로부터 분류를 집계하기 때문에 오버피팅이 나타나는 나무의 영향력을 줄일 수 있음 \n",
        "\n",
        "- 중복을 허용하기 때문에 단일 데이터가 여러번 선택될 수도 있음, 이를 배깅 이라고 함 \n",
        "\n",
        "- 나무를 만들 때는 모든 속성(feature)들에서 임의로 일부를 선택하고 그 중 정보 획득량이 가장 높은 것을 기준으로 데이터를 분할한다. 만약 데이터 세트에 n개의 속성이 있는 경우 n제곱근 개수만큼 무작위로 선택하는 것이 일반적이다"
      ],
      "metadata": {
        "id": "YbADmMtGTcGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델의 accuracy score가 99%가 나왔다면 바로 배포해서 사용할 수 있을까요?\n",
        "\n",
        "- NO 99% 가 나왔기에 단순히 좋다고 단언할 수 는 없음 . \n",
        "\n",
        "- Domain의 편중(Bias) 되어있기 떄문인데 , \n",
        "예를 들어 부산에 눈이 1M 가까이 오는것을 예측하는 분류기를 만든다면, 정확도 99.9% 를 만들어질겁니다. 눈 거의 않오니까요 . 이경우는 True Positive 보다는 True Negative 만 전부 맞추게될겁니다. True Positive는 하나도 못맞추고요 . 이런 상황을 정확도의 역설이라고 하는데 이를 위해서 재현율이나 정밀도 F1스코어 이런 것들이 더 필요할것입니다. \n"
      ],
      "metadata": {
        "id": "_18W_Hi7UpAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Leakage가 무엇인가요? 예시와 어떻게 해결할 수 있는지를 설명해주세요\n",
        "\n",
        "우리가 모른다고 가정된 정보가 누설된 경우를 의미 \n",
        "예를들어 시간단위로 기록된 날씨 데이터가 있고 1~2시간 뒤를 예측해야 하는 상황입니다.\n",
        "그런데 이 데이터를 예측하고자, 일 평균,즉 하루 평균 날씨의 Feature를 만들어서 모델에 학습시켰습니다. 이러면 Data leakage 가 발생합니다. 당장 1시간 뒤의 날씨도 모르는데 하루치 시간을 통합해버린 , 우리가 알수없는 데이터를 학습시키게 되면 성능에 이상이 생길것이기 떄문  \n",
        "\n",
        "\n",
        "### 딥러닝과 머신러닝에 대한 분류\n",
        "\n",
        "- 머신러닝: 주어진 데이터를 인간이 먼저 처리함, 사람이 먼저 컴퓨터에 특정 패턴을 추출하는 방법을 지시하고, 그 이후 컴퓨터가 스스로 데이터의 특징을 분석하고 축적함,\n",
        "\n",
        "- 딥러닝 : 머신러닝에서 사람이 하던 패턴 추출 작업이 생략이 됨, 컴퓨터가 스스로 데이터를 기반으로 학습할 수 있도록 정해진 신경망을 컴퓨터에게 주고 어린아이가 학습하는 것처럼 경험 중심으로 학습을 수행함 .\n",
        "\n",
        "### 데이터 구축 프로세스\n",
        "1. 설계\n",
        "  - 요구사항을 분석하여 전체 시스템의 개념부터 설계까지 밑그림을 그리는 작업 \n",
        "2. 구축 \n",
        "  - 실제 데이터의 수집과 통합 및 분석을 통해 결과를 배포 하는 과정 \n",
        "3. 시험\n",
        "  - 목표와 맞는 외부 분석 시스템 업체를 선정하고 연계를 위한 서비스를 설계하고 구현한다로 알고 있음 \n",
        "\n",
        "4. 연계\n",
        "\n",
        "### CLI와 GUI의 특징\n",
        "- CLI\n",
        "  - 글자의 입출력을 통해 사용자와 컴퓨터 간 소통하는 방식\n",
        "\n",
        "  - 대표적인 CLI로는 윈도우의 cmd, 맥의 terminal, 리눅스의 terminal\n",
        "\n",
        "  - 키보드 + 명령어 사용 가능\n",
        "\n",
        "- GUI(Graphic User Interface)란?\n",
        "\n",
        "  - 사용자가 그래픽을 통해 사용자와 소통하는 방식\n",
        "\n",
        "  - 그래픽으로 전달되는 그림이나, 아이콘을 통해서 소통\n",
        "\n",
        "  - 키보드 + 마우스 모두 사용 가능\n",
        "\n",
        "### API란 무엇인가?\n",
        "\n",
        "  - API : API는 응용 프로그램에서 사용할 수 있도록, 운영 체제나 프로그래밍 언어가 제공하는 기능을 제어할 수 있게 만든 인터페이스를 뜻한다\n",
        "\n",
        "  - 인터페이스: 인터페이스(interface)는 컴퓨터 시스템끼리 정보를 교한하는 공유 경계를 의미한다\n",
        "  ex) 리모콘 - TV \n",
        "\n",
        "### 파이썬 가상환경(virtual env)과 도커의 차이점\n",
        "\n",
        "- 가장 결정적인 차이로 파이썬 관련 프로그램이 아니면 따로 무언갈 해주어야 합니다. 그리고 OS 독립이 아니라서 우분투에서 만든 virtualenv 환경이 윈도우에서 잘 안돌아갈수도 있음 .\n",
        "\n",
        "### on-premise와 cloud에 대한 차이점\n",
        "\n",
        "- 온 프레미스 : \n",
        "\n",
        " 필요한 시스템을 구축하기 위해서 하드웨어와 소프트웨어를 구입하여, 시스템 구성 상황에 맞게 환경을 구성하는 것을 말합니다.\n",
        " \n",
        "  즉 서버실과 혹은 데이터 센터와 같이 특정 공간에 IT 인프라를 구축하여 소프트웨어를 사용하는 방식입니다.\n",
        "\n",
        "  시스템을 구축하기 위한 물리적인 하드웨어 장비를 구매하는 비용이 들어가며, 부차적으로는 이를 관리 및 운용을 위한 유지보수 비용을 필요로 합니다.\n",
        "\n",
        "- 가장 큰 차이 : \n",
        "  서비스를 제공함에 있어 IT 자원을 누가 관리하느냐의 차이 \n",
        "  , \n",
        "  온 프레미스 : 서비스를 공급하는 서비스의 제공자가 직접적으로 IT 자원을 관리하는 주체 \n",
        "\n",
        "  클라우드 시스템 : 서비스를 공급하는 서비스 제공자는 IT 자원을 사용할 뿐, 대부분의 IT 자원 관리는 클라우드 서비스 제공자에게 제공받음 \n",
        "\n",
        " - 비용: 필요한만큼 수정하여 추가로 자원을 사용 가능 \n",
        "  하지만 온프레미스는 장비를 구매를 해야하니 큰 돈이 듬  \n",
        "\n",
        " - 시스템 유지 보수 : \n",
        "  온프레미스는 인프라를 직접 운영하고 관리하기 때문에 유지보수가 용이하지 못함, 하지만 클라우드 시스템은 인프라 관련 전문가들이 상시 대기중이기에 빠르게 대응 가능 \n",
        "\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "m83jJ6R2Z-fV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RDBMS 와 NoSQL의 특징 \n",
        " 1. 데이터베이스 \n",
        "   - 데이터를 저장하고 관리\n",
        "   - 구조화된 정보 및 데이터의 체계적인 집합 .\n",
        " 2. DBMS(DataBase Management System):\n",
        "   - 사용자와 데이터베이스 사이에서 사용자의 요구에 따라 정보를 생성해주고 DB를 관리해주는 소프트웨어 \n",
        "\n",
        " 3. sQL (Structured Query Language):\n",
        "   - 관계형 데이터베이스 관리 시스템에 저장된 데이터를 관리하기 위해 설계된 프로그래밍 언어 \n",
        "\n",
        " 4. RDBMS ( Relational DataBase Management System)\n",
        "   - 관계형 데이터베이스 관리 시스템을 의미 \n",
        "   - 관계형 데이터베이스를 관리하며 관계형 데이터 모델을 기초로 두고 모든 데이터를 2차원 테이블 형태로 표현 \n",
        "   - 테이블 간 관계를 가질 수 있다는 것이 가장 큰 특징 \n",
        "\n",
        "   - 테이블에 따라 데이터를 저장하여야 하므로 명확한 데이터 구조를 보장( 데이터 무결성) \n",
        "\n",
        "   변경될 여지가 없고, 명확한 스키마가 사용자와 데이터에게 중요한 경우에 사용 \n",
        "\n",
        " 5. NoSQL \n",
        "   - 테이블 간 관계를 정의하지 않기 때문에 테이블간 관계를 맺을 수 없음 \n",
        "   - 다른 형태의 데이터를 저장\n",
        "   - 다른 구조의 데이터를 같은 컬렉션에 추가 가능 \n",
        "\n",
        "   - 장점 : 스키마가 없어서 유연하며 자유로 데이터 구조 저장된 데이터를 조정하고 새로운 필드 추가 가능 \n",
        "\n",
        "   - 단점: \n",
        "   \n",
        "    - 스키마가 존재하지 않기에 명확한 데이터 구조를 보장하지 않음 \n",
        "     - 데이터가 여러 컬렉션에 중복되어 있기에 변경시 모든 컬렉션에서 수정해줘야 함 \n",
        "\n",
        "    - 정확한 데이터 구조를 알 수 없고 데이터가 변경/확장이 될 수 있는 경우에 사용 \n",
        "\n",
        "    - 데이터베이스를 수평으로 확장해야 하는 경우 ( 많은 양의 데이터를 다룰 경우 )사용 \n",
        "\n",
        "### 비정형 데이터와 정형 데이터를 다룰 때 주의해야 할 점 \n",
        "\n",
        "\n",
        "- 이메일 해킹사건과 같이 정형 데이터로부터 2차, 3차 가공되는 비정형 데이터의 유출사고가 발생되어 보안이 요구된 정형 데이터의 연쇄 유출이 우려되고 있다.\n",
        "\n",
        "### 웹과 모바일에서 데이터를 수집 및 분석하는 경우 주의해야 될 점\n",
        "\n",
        "- 개인정보가 있거나 가져가면 안되는 정보일 경우 저작권에 걸려 법적 문제까지 갈 수 있음, robot.txt 를 참조해야함 \n",
        "\n",
        "### AB Test에 대해 설명하세요\n",
        "\n",
        "- AB test란 디지털 환경에서 전체 실사용자를 대상으로 대조군과 실험군으로 나누어서 어떤 특정한 UI나 알고리즘의 효과를 비교하는 방법론 \n",
        "\n",
        " -  노출빈도분산 방식 \n",
        "\n",
        " -  사용자분산 방식, \n",
        "\n",
        " -  시간대분산 방식\n",
        "\n",
        " \n",
        " 노출 분산 방식\n",
        "\n",
        "  - 방법론 : AB Test가 진행되는 페이지가 렌더링 될 때 비율로 A와 B를 다르게 노출시킴 \n",
        "\n",
        "  - 특징 : 가장 통계적 유의성이 높지만, UI /UX의 경우 사용자들에게 혼란을 줄 수 있음 \n",
        "\n",
        "  - 적합한 목적 : 알고리즘 테스트에 적합함 \n",
        "\n",
        "  사용자 분산 방식 \n",
        "  - 방법론 사용자를 A 그룹과 B그룹으로 분리하여 고정적으로 다른 Variation을 노출 시킴 \n",
        "\n",
        "  - 특징 : 사용자 별로 고정 UI/UX가 나오기 때문에 UI/UX 테스트에 적합하지만, 특정 Heavy User에 따라 결괏값이 왜곡될 수 있음 \n",
        "\n",
        "  - 적합한 테스트 목적 : UI/UX 테스트에 적합함 \n",
        "\n",
        " 시간 분할 방식 \n",
        " - 방법론 : 초~분 단위 정도로 시간대를 세밀하게 분할하여 A안과 B안을 노출 시킴 \n",
        "\n",
        " - 특징 : 보안/설계 상의 문제로 분산 방식이 어려울 때 , 상대적으로 쉽게 활용 할 수 있음 \n",
        "\n",
        " - 적합한 목적 : 노출/사용자 분산 방식을 사용할 수 없는 경우 대안적 활용 \n",
        "\n",
        "AB 신뢰하는 방법 \n",
        "\n",
        "AB Test를 실제 수행하였을 경우, AA test 와 P-value 분석을 사용\n",
        "\n",
        "AA test : AB test를 수행하기 전에 분산된 트래픽에 대해 동일한 Variation을 동시에 보여주고 차이가 있는지 없는지를 먼저 확인 후에 차이가 없다면 AB test를 진행시켜 차이가 발생하는지를 확인하는것\n",
        "\n",
        "\n",
        "## \"통계학적으로 유의미한 차이\"에 대해 설명해주세요. 어떤 경우에 이렇게 말하는지, 그리고 어떻게 하면 그 차이를 알 수 있는지도 같이 포함해주세요\n",
        "\n",
        "- 통계적 유의하다: 통계적 기법을 적용해서 어떤 가설, 혹은 실험 결과 자료를 분석했을 시 연구자의 생각이 단순히 우연이라고 생각되지 않을 정도로 맞을 가능성이 높다는 것을 의미함"
      ],
      "metadata": {
        "id": "8tjm5Odl0EYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Box Plot과 Histogram의 차이를 설명\n",
        "\n",
        "Boxplot : outlier를 제거하고 사분위수를 이용하여 가운데 50% 의 데이터를 통해 그래프를 생성함, 이를 통해 중앙값을 비롯한 각 사분위수의 범위, 최대값, 최소값을 알 수 있음 .\n",
        "\n",
        "Histogram : \n",
        "- 빈도수를 표현하는 막대 그래프 \n",
        "\n",
        "- 사각형의 높이는 구간의 밀도와 동일\n",
        "\n",
        "- 히스토그램의 전체 영역은 데이터의 개수와 동일\n",
        "\n",
        "Boxplot : \n",
        "\n",
        " - 데이터의 분포 형태 확인 및 분석에 주요한 변수 도출을 위해 사용하는 방법 \n",
        "\n",
        " - 자료의 크기 순서를 나타내는 순서 통계량을 이용하여 요약 정리하는 방법 \n",
        "\n",
        " - ( 순서통계량: 최소값, 제1사분위수, 중앙값, 제3사분위수, 최대값 ) \n",
        "\n",
        " - 사분위수를 한눈에 볼 수 있음\n",
        "\n",
        " - 데이터 분포의 대칭성 확인 \n",
        "    - 좌우대칭이면 중위수가 상자의 중심부에 위치\n",
        "\n",
        "    - 비대칭이면 중위수가 상자의 중심부에 위치하지 않음\n",
        "\n",
        " - 상자의 길이가 길면 자료값이 넓게 분포함을 의미, 좁을땐 데이터가 중앙값을 중심으로 밀집되어 있음을 의미 \n",
        "\n",
        " - 시사점 \n",
        "   - 이상치 확인\n",
        "   - 주요변수 확인 \n",
        "\n",
        "histogram 은 데이터의 범위, 데이터가 집중된 곳이나 대칭성을 보기 위해 사용하고 \n",
        "\n",
        "boxplot은 중앙값을 비롯한 각 사분위수의 범위, 최대값, 최소값을 알 수 있음 \n",
        "\n",
        "\n",
        "### 1-sample t-test와 2-sample t-test의 차이에 대해서 설명해주세요.\n",
        "\n",
        "1. T test \n",
        " - 모집단의 표준편차가 알려지지 않았을 때 정규분포의 모집단에서 모은 샘플의 평균값에 대한 가설검정\n",
        "\n",
        "2. T test의 목적 \n",
        "\n",
        "  - 두개의 집단이 같은지 다른지 비교하기 위해 사용 \n",
        "\n",
        "  - 이를 알기 위해 두 집단의 샘플의 평균값을 비교하고, 두집단의 차이가 우연히 발생했을 확률을 구하므로서 t-test에 대한 결론을 구함 \n",
        "\n",
        "  - 즉, 두 집단의 평균값이 통계적으로 같은지 다른지를 확인 \n",
        "\n",
        "3. One-side test vs Two side test \n",
        "\n",
        "Two side (tail /direction) test : 샘플 데이터의 평균이 X와 같다 / 같지 않다를 검정하는 내용 \n",
        "\n",
        "One side test : 샘플 데이터의 평균이 X보다 크다 혹은 작다 / 크기 않다 작지 않다, 를 검정하는 내용 \n",
        "\n",
        "4. One Sample T-test \n",
        " 1개의 sample 값의 평균이 특정값과 동일한지 비교, \n",
        "  ex) 동전이 공정한지 확인하려고 할때 : P(x=H) = 0.5 \n",
        "\n",
        "5. Two Sample T-test \n",
        " - 2개의 sample 값들의 평균이 서로 동일한지 비교, \n",
        "\n",
        " - 2개의 동전(500원짜리 vs 100원짜리)을 여러번 던져서 p(h)의 평균이 유사한지 \n",
        "   1. 귀무가설 : 두 확률은 같다 (차이가 없다 .)\n",
        "\n",
        "### ANOVA test에 대해서 설명해주세요. 사후검정은 무엇이고 왜 해야하나요?\n",
        "\n",
        "### Outlier의 판단 기준 \n",
        "\n",
        "- 이상치(Outlier)란, 보통 관측된 데이터의 범위에서 많이 벗어난 아주 작은 값이나 큰 값을 말한다\n",
        "\n",
        "1. Standard Deviation \n",
        "  데이터의 표준편차를 이용하여 이상치를 탐색\n",
        "  \n",
        "  z-score는 해당 데이터가 평균으로부터 얼마의 표준편차만큼 벗어나 있는지를 의미 \n",
        "  \n",
        "2. IQR \n",
        "IQR 은 Q3에서 Q1을 뺀 값 ( Q3위로 상위 25% Q1 아래로는 하위 25% ) IQR값은 Q3-Q1 값 \n",
        "\n",
        "(Q1-1.5*IQR) 보다 작거나 (Q3+1.5*IQR) 보다 큰 데이터는 이상치로 처리 \n",
        "  \n"
      ],
      "metadata": {
        "id": "KaBYbTHsyiGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### type 1 error  and type 2 errors\n",
        "1. type 1error \n",
        "  - 귀무가설이 실제로 참이지만, 귀무가설을 기각하는 오류 \n",
        "  - 실제 음성을 양성으로 판정\n",
        "\n",
        "  - 거짓 양성 또는 알파 오류라 불림\n",
        "  \n",
        "  - Type 1 error 0.05 및 5% 유의수준은 귀무가설이 5% 확률로 잘못 기각된다는 의미 \n",
        "  \n",
        "2. type 2 error \n",
        "  - 귀무가설이 실제로 거짓이지만 귀무가설을 채택하는 오류 \n",
        "\n",
        "  - 실제 양성인 것을 음성으로 판정\n",
        "\n",
        "  - 거짓 음성 또는 베타 오류라 불림 \n"
      ],
      "metadata": {
        "id": "xm1RL4t2mHV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 큰수의 법칙 \n",
        "\n",
        "- 큰 수의 법칙(law of large numbers, LLN)은 경험적 확률과 수학적 확률 사이의 관계를 나타내는 법칙으로, 표본집단의 크기가 커지면 그 표본평균이 모평균에 가까워짐을 의미한다. 따라서 취합하는 표본의 수가 많을수록 통계적 정확도는 올라가게 된다."
      ],
      "metadata": {
        "id": "kox_1EtkEecc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 중심극한정리 \n",
        "\n",
        "- 표본 평균의 분포는 정규 분포에 근사하게 됨 \n",
        "\n",
        "- 모집단의 모양이 어떻든 중심극한 정리는 성립 \n",
        "\n",
        "- 심지어는 표본을 추출하는 모집단이 서로 독립적이라면 여러 모집단에서 추출한 표본이더라도 표본 평균의 분포는 정규 분포에 근사하게 됨 \n",
        "\n",
        "- 중요한 이유 : 표본을 접할때 평균과 비교를 많이하게 되는데 이와 관련된 현상인 중심극한 정리를 염두해두고 얻어진 이론이 많기 때문 \n"
      ],
      "metadata": {
        "id": "IBU47q0OZ4Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selection Bias가 무엇인지 예시와 함께 설명해보세요. 그리고 결측치 처리와 같은 데이터 핸들링 기법이 어떻게 Selection Bias를 악화시킬 수 있을까요?\n",
        "\n",
        "- 선택 편향, 표본 편향 : 표본을 잘못 선택함으로써 통계 분석이 왜곡되는 것을 뜻함 , \n",
        "\n",
        "예를들어... 담배를 단순히 좋아하는지 싫어하는지에 대해서 설문조사를 할건데, 금연센터 직원들을 상태로 설문조사를 하는 상황임 \n",
        "\n",
        "\n",
        "### Extrapolation이 무엇인가요? 사용할 때의 유의사항은 무엇인가요?\n",
        "\n",
        "- 외삽법 : 얻을수 있는 자료가 한정되어 있어, 그 이상의 한계를 넘는 값을 얻고자 할 때 씀 ( 사전적 의미) \n",
        "\n",
        "이전의 실험으로 부터 얻은 데이터들에 비추어, 아직 경험/실험하지 못한 경우를 예측해본 기법 \n",
        "\n",
        "예를들어 매년 여름에 장마가 찾아왔다는 데이터를 통해 올해 여름에도 장마가 올것을 유출 하는것 \n",
        "\n",
        "하지만 간과한 변수나, 한번도 경험하지 못한 돌발 변수의 출현등으로 다르게 흘러갈수 있음 ( 지구온난화) \n",
        "\n",
        "### 데이터의 크기가 커짐에 따라 p-value는 더 이상 유효하지 않다라고 하는 주장\n",
        "\n",
        "- sample size가 크다면 p -value 자체는 대체로 유의하게 나옴 \n",
        "\n",
        "- 데이터 수가 크다면 신뢰구간은 좁아지고 p-value도 유의하게 나오는데 이런 경우엔 결과를 별로 신뢰하지 못하게 됨 ( 빅데이터의 저주 ) \n",
        "\n",
        "- 데이터 분포를 봤을 때 치우져져 있다면 정보가 쏠려있을 것이고 치우쳐져있지 않은 반대쪽 정보가 부족할 것 , 정보의 배분을 위해 전체적인 표본의 분포를 고르게 배분할 필요가 있음  (표본 수 결정의 중요성 \n",
        "\n",
        "### 포아송 분포 \n",
        "\n",
        "- 푸아송 분포(Poisson分布, 영어: Poisson distribution)는 확률론에서 단위 시간 안에 어떤 사건이 몇 번 발생할 것인지를 표현하는 이산 확률 분포\n",
        "\n",
        "- 응용 : 일정 주어진 시간 동안에 도착한 고객의 수 \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9DGMh8SHjK3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### R과 R^2의 차이는 무엇인가요. 각자 어떻게 해석하면 되나요?\n",
        "\n",
        "\n",
        "### mean과 median , 어떤 경우에 mean이 아닌 median을 써야하나요?\n",
        "\n",
        "- mean : \n",
        "\n",
        "- median :  편향된 데이터와 이상치 때문에 그릇된 정보를 제공하는 경우가 있음  , 중앙값, mean에서 터지는 문제점을위함 , 데이터가 편향되어 있거나, 이상치 때문에 중앙값을 가져와 해결하는것 "
      ],
      "metadata": {
        "id": "wQ2RWdN1uYcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bias의 종류와 이를 통제하는 방법은 무엇일까요?\n",
        "\n",
        "- 확증 편향 : 자신이 본래 믿고 있는대로 정보를 선택적으로 받아들이고 임의로 판단하는 편향 \n",
        "\n",
        "- 기준점 편향 : 분석가가 가장 처음에 접하는 정보에 지나치게 매몰되는 편향 \n",
        "\n",
        "- 선택 지원 편향 : 본인이 의사결정을 내리는 순간, 그 선택의 긍정적인 부분에 대해 더 많이 생각하고 그 결정에 반대되는 증거를 무시하게 되는 편향 \n",
        "\n",
        "- 분모 편향: 분수 전체가 아닌 분자에만 집중하여 현황을 왜곡하여 판단하게 되는 편향 \n",
        "\n",
        "안록산의 난 ( 사망자 4천만 , 15%) vs 2차 세계대전 ( 사망자 1억, 4% ) \n",
        "\n",
        "이떄 인구가 다름 (분모)\n",
        "\n",
        "- 생존자 편향 : 소수의 성공한 사례를 일반화된 것으로 인식함으로써 나타나는 편향 \n",
        "\n",
        " 전투기의 총탄피해는 날개와 꼬리 부분이 많아서 그부분을 보강하려 하였으나, 실질적으론 조종석과 엔진부가 중요했음, 조종석과 엔진부에 피격당한 전투기는 귀환하지 못했기 때문 "
      ],
      "metadata": {
        "id": "B-I9ovDkU1J3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 신뢰 구간 ( Confidence Interval, CI)\n",
        "\n",
        "- 신뢰구간은 모수가 실제로 포함될 것으로 예측된 범위 \n",
        "\n",
        "- 집단 전체를 연구하는 것은 불가능하므로, 샘플링된 데이터를 기반으로 모수의 범위를 추정하기 위해 사용됨 , 따라서 신뢰 구간은 샘플링된 표본이 연구중인 모집단을 얼마나 잘 대표하는지 측정하는 방법 \n",
        "\n",
        "### 가설검정을 위한 정규성 테스트 \n",
        "\n"
      ],
      "metadata": {
        "id": "QgHkVF9PZA6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 분석 프로세스 \n",
        "1. 문제 정의\n",
        " - 분석 대상의 이해 \n",
        " - 객관적이고 구체적으로 분석 대상 정의 \n",
        "2. 데이터 수집\n",
        " - 필요한 데이터요건 정의\n",
        " - 데이터 소재 파악 및 확보\n",
        "3. 데이터 전처리 \n",
        " - 오류 사항 점검 및 조치 \n",
        " - 데이터 구조 및 특성 변경 \n",
        "\n",
        "4. 데이터 모델링\n",
        " - 다양한 관점을 반영한 데이터 설계\n",
        " - 관련 테이블간 관계 설정  \n",
        "5. 시각화 및 탐색 \n",
        " - 다양한 유형의 데이터 시각화 \n",
        " - 문제 해결을 위한 인사이트 도출 \n",
        "\n",
        " ### 데이터 분석 시 가장 어려운 점은 무엇인가요? 왜 그렇게 생각하시나요? \n",
        "\n",
        " - 도메인 지식 부족 \n",
        "\n",
        " ### 데이터 분석을 하면서 데이터 분석가가 보게 될 수 있는 문제는 어떤 것이 있을까요?\n",
        "\n",
        "  - 인지 편향에 빠지는 문제 , 데이터랑 사랑에 빠져버리는거죠  \n",
        "\n",
        "### EDA를 하면서 가장 흥미로웠었던 인사이트는 어떤 것이었나요? \n",
        " - 게임 국가별 니즈를 파악하는데, 전체적으로 액션장르가 공통적으로 인기가 있었습니다. 하지만 선형회귀를 사용하여 예상치보다 높은 장르, 즉 범국가적인 취향보다 더 인기가 있는 장르를 뽑았을때 국가별로 다들 차이가 있었습니다. 특히 EU, NA 는 슈터 장르가 인기있었으니 일본은 플랫폼 장르가 있기 있었죠 , \n",
        "\n",
        "\n",
        "### \"상관관계는 인과관계를 의미하지 않는다\"라는 말이 있습니다. 설명해주실 수 있나요?\n",
        "\n",
        "\n",
        "인과관계는 선행하는 한 변인이 후행하는 다른 변인의 원인이 되고 있다고 믿어지는 관계다. 쉽게 말해 '원인과 결과'의 관계다.\n",
        "\n",
        "상관관계는 한 변수의 변화에 따라 다른 변수도 변화하는 지에 대한 선형 관계다. 쉽게 말해 '두 변수 간에 일정한 관계가 있음'을 뜻한다.\n",
        "\n",
        "인과관계는 상관관계에서 원인과 결과의 관계까지 명확히 밝히지만, 상관관계만으로는 인과관계를 정확히 밝히지 못한다.\n",
        "\n",
        "예를 들어 키와 몸무게는 일정한 상관관계가 있지만 키가 크다고 반드시 몸무게가 많이 나간다고 할 수 없다. 따라서 상관관계가 있다고 인과관계가 있다고 할 수 없다.\n",
        "\n",
        "    또 다른 예\n",
        "    한 연구자가 아이스크림 판매량의 연중 증감 추이를 확인했다. 그리고 연중 익사 사망자의 증감 추이를 함께 놓고 두 변인 간의 상관분석을 시행해 보았다. 결과는 놀라웠다. 무서울 정도로 명백한 상관관계가 나타나고 있었다. 아이스크림 판매량이 급증하는 동안, 익사 사망자 수도 함께 증가하고 있었으며, 판매량이 감소하는 동안 익사 사망자 수도 감소하고 있었던 것이었다.연구자는 몸서리를 치면서 다음과 같은 결론을 내렸다. \"익사 사망자의 증감은 아이스크림이 그 원인이다.\"\n"
      ],
      "metadata": {
        "id": "pdPavnjQf1bs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 분석가의 목적 \n",
        " - 시장 조사 제품 조사 등으로 부터 얻은 데이터를 이용하여 기업에 최대한의 이익을 안겨주는것"
      ],
      "metadata": {
        "id": "yU8V1Mp0rsIM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3myrEQXUkJJ"
      },
      "outputs": [],
      "source": []
    }
  ]
}