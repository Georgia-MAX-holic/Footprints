{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbaLajt1dAOOmpZLRqUOZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Georgia-MAX-holic/theory/blob/main/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/LightGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost ( eXtra Gradient Boost ) \n",
        "\n",
        "1. 주요 장점 \n",
        "  - 뛰어난 예측 성능 \n",
        "\n",
        "  - GBM 대비 빠른 수행 시간 ( CPU병렬 처리 , GPU 지원)\n",
        "\n",
        "  - 다양한 성능 향상 기능 \n",
        "\n",
        "     - 규제(Regularization) 기능 탑재 \n",
        "     \n",
        "     - Tree prunding \n",
        "\n",
        "  - 다양한 편의 기능 \n",
        "     - 조기 중단 ( Early Stopping) \n",
        "\n",
        "     - 자체 내장된 교차 검증 \n",
        "\n",
        "     - 결손값 자체 처리 \n",
        "\n"
      ],
      "metadata": {
        "id": "NTr7dBdq6h0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "XGBoost 조기 중단 기능 (Early Stopping) \n",
        "\n",
        "- XGBoost 는 특정 반복 횟수 만큼 더 이상 비용함수가 감소하지 않으면 지정된 반복횟수를 다 완료하지 않고 수행을 종료할 수 있음 \n",
        "\n",
        "- 학습을 위한 시간을 단축 시킬 수 있음. 특히 최적화 튜닝 단계}에서 적절하게 사용가능 \n",
        "\n",
        "- 너무 반복 횟수를 단축할 경우 예측 성능 최적화가 안된 상태에서 학습이 종료될 수 있으므로 유의 필요 \n",
        "\n",
        "- 조기 중단 설정을 위한 주요 파라미터 \n",
        "\n",
        "   - early_stopping_rounds\n"
      ],
      "metadata": {
        "id": "w2HfCAd48bFe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUHFf49u6TQb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# **LightGBM 개요**\n",
        "\n",
        "XGBoost 대비 장점 \n",
        "\n",
        "- 더 빠른 학습과 예측 수행 시간\n",
        "\n",
        "- 더 작은 메모리 사용량 \n",
        "\n",
        "- 카테고리형 피처의 자동 변환과 최적 분할( 원 - 핫 인코딩 ) \n",
        "등을 사용하지 않고도 카테고리형 피처를 최적으로 변환하고 이에 따른 노드 분할 수행 가능 \n",
        "\n",
        "\n",
        "LightGBM 트리 분할 방식 - 리프 중심 \n",
        "\n",
        "- 일반적은 GBM 계열의 트리 분할 방법은 트리의 깊이를 효과적으로 줄이기 위해 \" 균형 분할 방식\"을 사용 (오버 피팅에 가함 ) \n",
        "\n",
        "- 최대 손실 값을 가지는 리프 노드를 지속적으로 분할하면서 트리의 깊이가 깊어지고 비대칭적인 규칙 트리가 생성되는것이 특징 \n"
      ],
      "metadata": {
        "id": "i8qHBarBTSje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **사이킷런 래퍼 LightGBM 하이퍼파라미터** \n",
        "\n",
        "- n_estimators \n",
        "   - 반복을 수행하려는 트리의 개수 \n",
        "\n",
        "   - 기본값은 100\n",
        "\n",
        "- learning_rate \n",
        "   - 기본값은 \n",
        "\n",
        "- max_depth\n",
        "   - Depth wise 방식이 아닌 Leaf Wise 방식이므로 깊이가 상대적으로 더 깊다는 점 \n",
        "\n",
        "   - 0보다 작은 값을 지정하면 깊이에 제한이 없음 \n",
        "\n",
        "   - 기본값은 -1 \n",
        "\n",
        "\n",
        "- num_leaves \n",
        "   - 하나의 트리가 가질 수 있는 최대 리프 개수 \n",
        "   - 기본값은 31 "
      ],
      "metadata": {
        "id": "tSWDjwP-VUnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **LightGBM 과적합 감소 방법**\n",
        "\n",
        "모델 복잡도를 제어하는 주요 파라미터 \n",
        "\n",
        "-  num_leaves \n",
        "\n",
        "- min_child_samples\n",
        "\n",
        "- max_depth "
      ],
      "metadata": {
        "id": "fpq68vXCWBaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "d5eUwY-2WArW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_breast_cancer()"
      ],
      "metadata": {
        "id": "DfhZ0MMRZ5qk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_df = pd.DataFrame(data=dataset, columns = dataset.feature_names)"
      ],
      "metadata": {
        "id": "hbuxL_MFaAc2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_df[\"target\"] = dataset.target "
      ],
      "metadata": {
        "id": "iv8cpBjxQGxU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## data split => train / test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size=0.2, random_state=156)\n",
        "\n",
        "## data split => train => train / val\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=156)"
      ],
      "metadata": {
        "id": "Sa5qczRoRyQi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_wrapper = LGBMClassifier(n_estimators=400, learning_rate=0.05)"
      ],
      "metadata": {
        "id": "Ae0XLAOrR_n4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evals = [(X_tr, y_tr), (X_val, y_val)]"
      ],
      "metadata": {
        "id": "JzazlSFXSBIP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_wrapper.fit(X_tr, y_tr,\n",
        "                 early_stopping_rounds=50,\n",
        "                 eval_metric=\"logloss\",\n",
        "                 eval_set=evals,\n",
        "                 verbose=True\n",
        "                 )"
      ],
      "metadata": {
        "id": "gFQOZ5yXSB6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가\n",
        "\n",
        "preds = lgbm_wrapper.predict(X_test)\n",
        "pred_proba = lgbm_wrapper.predict_proba(X_test)\n",
        "\n",
        "## 모델 성능 평가 함수 선언 \n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
        "\n",
        "    confusion = confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    f1 = f1_score(y_test, pred)\n",
        "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
        "\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n"
      ],
      "metadata": {
        "id": "czefaHn9SCaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_clf_eval(y_test, preds, pred_proba)"
      ],
      "metadata": {
        "id": "_AAvSGmMSWpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OByuHuosQdAy"
      }
    }
  ]
}